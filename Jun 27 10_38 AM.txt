
#MR
import numpy as np
import matplotlib.pyplot as plt
def generate_dataset(n):
    x = []
    y = []
    random_x1 = np.random.rand()
    random_x2 = np.random.rand()
    for i in range(n):
        x1 = i
        x2 = i / 2 + np.random.rand() * n
        x.append([1, x1, x2])
        y.append(random_x1 * x1 + random_x2 * x2 + 1)
    return np.array(x), np.array(y)


x, y = generate_dataset(200)
plt.rcParams["legend.fontsize"] = 12
fig = plt.figure()
ax = fig.add_subplot(projection="3d")
ax.scatter(x[:, 1], x[:, 2], y, label="y")
ax.set_xlabel("X1")
ax.set_ylabel("X2")
ax.set_zlabel("Y")
ax.set_title("3D Scatter Plot")
# ax.legend()
ax.view_init(elev=45, azim=0)
plt.show()



#LR
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
dataset = pd.read_csv('data.csv')
dataset['Gender'] = dataset['Gender'].map({'Male': 0, 'Female': 1})
X = dataset[['Gender', 'Age', 'EstimatedSalary']]
y = dataset['Purchased']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
model = LogisticRegression(random_state=0)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:\n', cm)
print('Accuracy Score:', accuracy_score(y_test, y_pred))
print('Classification Report:\n', classification_report(y_test, y_pred))


#KNN

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import neighbors,datasets
n_neighbors=5
iris=datasets.load_iris()
x=iris.data[:,:2]
y=iris.target
h=.02

cmap_light=ListedColormap(['blue','orange','red'])
cmap_bold=ListedColormap(['#FF0000','#00FF00','#00AAFF'])
clf=neighbors.KNeighborsClassifier(n_neighbors,weights='distance')
clf.fit(x,y)

x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1
y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),np.arange(y_min, y_max, 0.02))

z=clf.predict(np.c_[xx.ravel(),yy.ravel()])
z=z.reshape(xx.shape)
plt.figure()
plt.pcolormesh(xx,yy,z,cmap=cmap_light)
plt.scatter(x[:,0],x[:,1],c=y,cmap=cmap_bold)
plt.xlim(xx.min(),xx.max())
plt.ylim(yy.min(),yy.max())
plt.title("3-ClassClassification(k=%i)"%(n_neighbors))
plt.show()

#NB

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
dataset = pd.read_csv('cancer.csv')
dataset.head()
dataset.info()
dataset = dataset.drop(["id"],axis=1)
dataset = dataset.drop(["Unnamed: 32"],axis=1)
M = dataset[dataset.diagnosis=="M"]
B = dataset[dataset.diagnosis=="B"]
plt.scatter(M.radius_mean,M.texture_mean,color='red')
plt.scatter(B.radius_mean,B.texture_mean,color='lime')
plt.show()


#KMeans
#HC
#PCA

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.decomposition import PCA
country_data = pd.read_csv('Country-data.csv')
X = country_data[['gdpp', 'child_mort']]
X_normalized = (X - X.mean()) / X.std()
kmeans = KMeans(n_clusters=3, random_state=42).fit(X_normalized)
kmeans_labels = kmeans.labels_
kmeans_centroids = kmeans.cluster_centers_
plt.figure(figsize=(8, 6), dpi=100)
plt.scatter(X_normalized.values[:, 0], X_normalized.values[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6, edgecolors='w')
plt.title('K-Means Clustering')
plt.show()


Z = linkage(X_normalized, 'ward')
plt.figure(figsize=(10, 5))
dendrogram(Z)
plt.title('Hierarchical Clustering Dendrogram')
plt.show()


X_pca = PCA(n_components=2).fit_transform(X_normalized)
plt.figure(figsize=(8, 6), dpi=100)
plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6, edgecolors='w')
plt.title('PCA of the Dataset')
plt.show()


#RandomForest

from sklearn.ensemble import RandomForestClassifier 
from sklearn.datasets import load_iris 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score, confusion_matrix 
import seaborn as sns 
import matplotlib.pyplot as plt 
X, y = load_iris(return_X_y=True) 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train) 
y_pred = rf_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred) 
print(f"Accuracy of Random Forest Classifier: {accuracy:.4f}") 
plt.figure(figsize=(8, 6)) 
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='d', cbar=True) 
plt.xlabel('Predicted Labels') 
plt.ylabel('True Labels') 
plt.title('Confusion Matrix') 
plt.show()



